{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing with some EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "불필요한 열 제거, 특정 ID 변수를 categorical type으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 열\n",
    "col_notuse = ['ADID', '노출 ID', 'SSP 입찰ID', 'DSP 입찰ID', 'AX 낙찰ID', 'WUID (웹 유저 ID)', '광고 응답 광고주 도메인','OS 버전 ID']\n",
    "col_use = ['시각', 'ADID 타입', 'DSP ID', '매체 ID', '애드유닛 ID', '플랫폼', 'OS 종류', '사이즈 ID',\n",
    "       '환율', '광고 응답 소재 카테고리', '국가코드 ID', 'P1', 'P2', 'P3', 'P4', 'P5',\n",
    "       'winning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # chunk to pickle(train dataset)\n",
    "# tp = pd.read_csv('dataset_round1/round1_train.csv', iterator=True, chunksize=1000000)\n",
    "# df = pd.concat(tp, ignore_index=True)\n",
    "# # df.to_pickle('train_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Load/save는 pickle format 이용함\n",
    "# df = pd.read_pickle('train_full.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 데이터 중\n",
    "* 낙찰 O : 약 200만개\n",
    "* 낙찰 X : 약 530만개\n",
    "\n",
    "> binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불필요한 열 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df.columns[:-6]:\n",
    "#     print(f'Unique values of column {col} : {len(df[col].unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불필요한 열 선정 결과\n",
    "\n",
    "> Drop cols : ADID, 노출 ID, SSP 입찰ID, DSP 입찰ID, AX 낙찰ID, WUID (웹 유저 ID), 도메인, OS 버전 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cols = df.columns.drop(col_notuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle('train.pkl') # 4.3s(compressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID cols to categorical coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_round1/round1_train.csv', usecols=col_use) # 34.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('dataset_round1/round1_test.csv', usecols=df.columns.drop(['P5','winning']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSP ID, 매체 ID, 애드유닛 ID to categorical(from ID to integer)\n",
    "col_cat = ['DSP ID', '매체 ID', '애드유닛 ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "from copy import deepcopy\n",
    "\n",
    "for col in col_cat:\n",
    "    series_whole = pd.concat([df[col],df_test[col]]).astype('category').cat.codes + 1\n",
    "    df[col] = series_whole[:len(df)]\n",
    "    df_test[col] = series_whole[len(df):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['시각','winning'])\n",
    "df_test = df_test.sort_values(by=['시각'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle('train_1.pkl')\n",
    "# df_test.to_pickle('test_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle('train.pkl') \n",
    "# df_test.to_pickle('test.pkl') # 1.6s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load\n",
    "df_train = pd.read_pickle('train.pkl')\n",
    "df_train = df_train[df_train.columns.drop(['P5'])] # P5는 사용불가능한 변수이므로 제거\n",
    "\n",
    "df_test = pd.read_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_price = ['P1','P2','P3','P4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.winning==1.0, col_price].corr() # 가격변수간 상관계수 탐색(낙찰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.winning==0.0, col_price].corr() # 가격변수간 상관계수 탐색(유찰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('train.pkl')\n",
    "df_test.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Datetime\n",
    "일시 및 초단위 시각을 직접 사용하는 것은 현재 Classification 문제에서 벗어난 Time-series analysis의 관점이므로 일부 변수로만 추출해서 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('train.pkl')\n",
    "df_test = pd.read_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.시각 = pd.to_datetime(df_train.시각, format='%Y%m%d%H%M%S')\n",
    "df_test.시각 = pd.to_datetime(df_test.시각, format='%Y%m%d%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('train.pkl') \n",
    "df_test.to_pickle('test.pkl') # 1.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Extraction\n",
    "## 주말여부\n",
    "df_train['weekend'] = df_train.시각.dt.dayofweek > 4\n",
    "df_train['weekend'] = df_train['weekend'].astype('int')\n",
    "df_test['weekend'] = df_test.시각.dt.dayofweek > 4\n",
    "df_test['weekend'] = df_test['weekend'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 시간대\n",
    "df_train['hour'] = df_train.시각.dt.hour\n",
    "df_test['hour'] = df_test.시각.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 요일\n",
    "df_train['dayofweek'] = df_train.시각.dt.dayofweek\n",
    "df_test['dayofweek'] = df_test.시각.dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('train.pkl')\n",
    "df_test.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "- Kernel Density Estimation plot으로 가격변수의 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win = df_train[df_train.winning==1.0]\n",
    "df_lose = df_train[df_train.winning==0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If normalized?\n",
    "df_norm = deepcopy(df_train)\n",
    "df_minmax = deepcopy(df_train)\n",
    "\n",
    "for col in col_price:\n",
    "    df_norm[col] = (df_norm[col]-df_norm[col].mean())/df_norm[col].std()\n",
    "    df_minmax[col] = (df_minmax[col]-df_minmax[col].min())/(df_minmax[col].max()-df_minmax[col].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm_win = df_norm[df_train.winning==1.0]\n",
    "df_norm_lose = df_norm[df_train.winning==0.0]\n",
    "\n",
    "df_minmax_win = df_minmax[df_train.winning==1.0]\n",
    "df_minmax_lose = df_minmax[df_train.winning==0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean-Normalized\n",
    "fig, axes = plt.subplots(2,2,figsize=(12,12))\n",
    "for idx, col in enumerate(col_price):\n",
    "    sns.kdeplot(df_norm_win[col], label='Win', ax=axes[idx//2, idx%2])\n",
    "    sns.kdeplot(df_norm_lose[col], label='Lose', ax=axes[idx//2, idx%2])\n",
    "    axes[idx//2,idx%2].legend()\n",
    "    axes[idx//2,idx%2].set_title(f'KDE Plot for {col}')\n",
    "plt.suptitle('Mean-Normalized Price Variables', fontsize=15)\n",
    "plt.show() # 32.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimax-Normalized\n",
    "fig, axes = plt.subplots(2,2,figsize=(12,12))\n",
    "for idx, col in enumerate(col_price):\n",
    "    sns.kdeplot(df_minmax_win[col], label='Win', ax=axes[idx//2, idx%2])\n",
    "    sns.kdeplot(df_minmax_lose[col], label='Lose', ax=axes[idx//2, idx%2])\n",
    "    axes[idx//2,idx%2].legend()\n",
    "    axes[idx//2,idx%2].set_title(f'KDE Plot for {col}')\n",
    "plt.suptitle('Minimax-Normalized Price Variables', fontsize=15)\n",
    "plt.show() # 34.8s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기존 분포에서는 낙찰/유찰 간 가격변수의 분포가 잘 구분되지 않음 > 로그변환 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2,figsize=(12,12))\n",
    "for idx, col in enumerate(col_price):\n",
    "    sns.kdeplot(np.log1p(df_win[col]), label='Win', ax=axes[idx//2, idx%2])\n",
    "    sns.kdeplot(np.log1p(df_lose[col]), label='Lose', ax=axes[idx//2, idx%2])\n",
    "    axes[idx//2,idx%2].legend()\n",
    "    axes[idx//2,idx%2].set_title(f'KDE Plot for {col}')\n",
    "plt.suptitle('Log-Transformed Price Variables', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종 : P1-P4 데이터에 대해 log1p 변환 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_price:\n",
    "    df_train[col] = np.log1p(df_train[col])\n",
    "    df_test[col] = np.log1p(df_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('train.pkl') \n",
    "df_test.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Data type / Variable Name setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('train.pkl')\n",
    "df_test = pd.read_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['Datetime', 'ADID_type', 'DSP_ID', 'Media_ID', 'Adunit_ID', 'Platform', 'OS_type', 'Size_ID',\n",
    "       'Ex_Rate', 'Category', 'Country_ID', 'P1', 'P2', 'P3', 'P4', 'weekend',\n",
    "       'hour', 'dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = colnames + ['Class']\n",
    "df_test.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_int = ['ADID_type', 'DSP_ID', 'Media_ID', 'Adunit_ID', 'Platform', 'OS_type', 'Size_ID',\n",
    "           'Country_ID', 'weekend', 'hour', 'dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value at Country_ID > treat with Mode\n",
    "df_train['Country_ID'] = df_train.Country_ID.fillna(df_train.Country_ID.mode()[0])\n",
    "df_test['Country_ID'] = df_test.Country_ID.fillna(df_test.Country_ID.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set integer columns\n",
    "df_train[col_int] = df_train[col_int].astype('int64')\n",
    "df_test[col_int] = df_test[col_int].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('train.pkl') \n",
    "df_test.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Treatment\n",
    "- 모든 서브카테고리까지 포함하기에는 너무 많은 variable 생성됨</br>\n",
    "- 특정 Main Category(0~26, 0:NA)에 속하는 여부만 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('train.pkl')\n",
    "df_test = pd.read_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category fillna with str NA\n",
    "df_train.Category = df_train.Category.fillna('NA')\n",
    "df_test.Category = df_test.Category.fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category treatment\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "cat_train = []\n",
    "cat_test = []\n",
    "\n",
    "for i in tqdm(range(len(df_train))):\n",
    "    cat_train.append(df_train.Category[i].split('%2C'))\n",
    "\n",
    "print(len(cat_train))\n",
    "\n",
    "for i in tqdm(range(len(df_test))):\n",
    "    cat_test.append(df_test.Category[i].split('%2C'))\n",
    "\n",
    "print(len(cat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = 'IAB91-38'\n",
    "int(st[3:st.find('-')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.find('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_treated = [] # for train\n",
    "for ls in tqdm(cat_train):\n",
    "    ls_treated = []\n",
    "    for item in ls:\n",
    "        if item == 'NA':\n",
    "            ls_treated.append(0)\n",
    "        else:\n",
    "            if item.find('-') == -1:\n",
    "                ls_treated.append(int(item[3:]))\n",
    "            else:\n",
    "                ls_treated.append(int(item[3:item.find('-')]))\n",
    "    \n",
    "    cat_train_treated.append(list(set(ls_treated))) # duplicate remove\n",
    "\n",
    "print(len(cat_train_treated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_test_treated = [] # for test\n",
    "for ls in tqdm(cat_test):\n",
    "    ls_treated = []\n",
    "    for item in ls:\n",
    "        if item == 'NA':\n",
    "            ls_treated.append(0)\n",
    "        else:\n",
    "            if item.find('-') == -1:\n",
    "                ls_treated.append(int(item[3:]))\n",
    "            else:\n",
    "                ls_treated.append(int(item[3:item.find('-')]))\n",
    "    \n",
    "    cat_test_treated.append(list(set(ls_treated))) # duplicate remove\n",
    "\n",
    "print(len(cat_test_treated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To dummy Variable (as IAB_n)\n",
    "for i in range(27):\n",
    "    colname_i = 'IAB_' + str(i)\n",
    "    df_train[colname_i] = 0\n",
    "    df_test[colname_i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Train data\n",
    "for idx, ls in tqdm(enumerate(cat_train_treated)):\n",
    "    for item in ls:\n",
    "        colname_i = 'IAB_' + str(item)\n",
    "        df_train.iloc[idx, df_train.columns.get_loc(colname_i)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Test data\n",
    "for idx, ls in tqdm(enumerate(cat_test_treated)):\n",
    "    for item in ls:\n",
    "        colname_i = 'IAB_' + str(item)\n",
    "        df_test.iloc[idx, df_test.columns.get_loc(colname_i)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.columns.drop(['Category'])]\n",
    "df_test = df_test[df_test.columns.drop(['Category'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.columns.drop(['Class']).tolist()+['Class']] # Class 맨뒤로 보내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('train.pkl') \n",
    "df_test.to_pickle('test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('atf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "057b2dfdcbeb6152fe7a6de916733e2aadd6aefdf07a18e5e9a0b06119769157"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
