{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Code\n",
    "### Contents\n",
    "> 1. Preprocessing w. some EDA\n",
    "> 2. Feature Selection w. Boosting Algorithm\n",
    "> 3. MLP model\n",
    "> 4. SGD Classifier\n",
    "> 5. Final Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing w. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Training data from chunks\n",
    "tp = pd.read_csv('data/round1_train.csv', iterator=True, chunksize=1000000)\n",
    "df = pd.concat(tp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불필요한 변수 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['시각', 'ADID', 'ADID 타입', 'DSP ID', '매체 ID', '애드유닛 ID', '플랫폼', 'OS 종류',\n",
       "       '사이즈 ID', '노출 ID', 'SSP 입찰ID', 'DSP 입찰ID', 'AX 낙찰ID', 'WUID (웹 유저 ID)',\n",
       "       '환율', '광고 응답 소재 카테고리', '광고 응답 광고주 도메인', '국가코드 ID', 'OS 버전 ID', 'P1',\n",
       "       'P2', 'P3', 'P4', 'P5', 'winning'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of column 시각 : 602696\n",
      "Unique values of column ADID : 537679\n",
      "Unique values of column ADID 타입 : 4\n",
      "Unique values of column DSP ID : 7\n",
      "Unique values of column 매체 ID : 456\n",
      "Unique values of column 애드유닛 ID : 986\n",
      "Unique values of column 플랫폼 : 3\n",
      "Unique values of column OS 종류 : 2\n",
      "Unique values of column 사이즈 ID : 3\n",
      "Unique values of column 노출 ID : 8494146\n",
      "Unique values of column SSP 입찰ID : 8525512\n",
      "Unique values of column DSP 입찰ID : 7684881\n",
      "Unique values of column AX 낙찰ID : 8525512\n",
      "Unique values of column WUID (웹 유저 ID) : 198624\n",
      "Unique values of column 환율 : 6\n",
      "Unique values of column 광고 응답 소재 카테고리 : 143\n",
      "Unique values of column 광고 응답 광고주 도메인 : 2474\n",
      "Unique values of column 국가코드 ID : 33\n",
      "Unique values of column OS 버전 ID : 13\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns[:-6]:\n",
    "    print(f'Unique values of column {col} : {len(df[col].unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 불필요한 열 선정 결과\n",
    "\n",
    "> Drop cols : ADID, 노출 ID, SSP 입찰ID, DSP 입찰ID, AX 낙찰ID, WUID (웹 유저 ID), 도메인, OS 버전 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 열\n",
    "col_notuse = ['ADID', '노출 ID', 'SSP 입찰ID', 'DSP 입찰ID', 'AX 낙찰ID', 'WUID (웹 유저 ID)', '광고 응답 광고주 도메인','OS 버전 ID']\n",
    "col_use = ['시각', 'ADID 타입', 'DSP ID', '매체 ID', '애드유닛 ID', '플랫폼', 'OS 종류', '사이즈 ID',\n",
    "       '환율', '광고 응답 소재 카테고리', '국가코드 ID', 'P1', 'P2', 'P3', 'P4', 'P5',\n",
    "       'winning']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID columns to Categorical Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv with selected columns\n",
    "df = pd.read_csv('data/round1_train.csv', usecols=col_use) # 34.3s\n",
    "df_test = pd.read_csv('data/round1_test.csv', usecols=df.columns.drop(['P5','winning'])) # 41s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSP ID, 매체 ID, 애드유닛 ID to categorical(from ID to integer)\n",
    "col_cat = ['DSP ID', '매체 ID', '애드유닛 ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "from copy import deepcopy\n",
    "\n",
    "for col in col_cat:\n",
    "    series_whole = pd.concat([df[col],df_test[col]]).astype('category').cat.codes + 1\n",
    "    df[col] = series_whole[:len(df)]\n",
    "    df_test[col] = series_whole[len(df):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['시각','winning'])\n",
    "df_test = df_test.sort_values(by=['시각'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Datetime\n",
    "일시 및 초단위 시각을 직접 사용하는 것은 현재 Classification 문제에서 벗어난 Time-series analysis의 관점이므로 일부 변수로만 추출해서 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.columns.drop(['P5'])] # P5 > 학습에 사용불가능한 가격변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6r/ndnspf4n6n7_m8rb9bs7qdvr0000gp/T/ipykernel_17150/1184950095.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.시각 = pd.to_datetime(df_train.시각, format='%Y%m%d%H%M%S')\n"
     ]
    }
   ],
   "source": [
    "# To datetime\n",
    "df_train.시각 = pd.to_datetime(df_train.시각, format='%Y%m%d%H%M%S')\n",
    "df_test.시각 = pd.to_datetime(df_test.시각, format='%Y%m%d%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Extraction\n",
    "# 주말여부\n",
    "df_train['weekend'] = df_train.시각.dt.dayofweek > 4\n",
    "df_train['weekend'] = df_train['weekend'].astype('int')\n",
    "df_test['weekend'] = df_test.시각.dt.dayofweek > 4\n",
    "df_test['weekend'] = df_test['weekend'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 시간대\n",
    "df_train['hour'] = df_train.시각.dt.hour\n",
    "df_test['hour'] = df_test.시각.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 요일\n",
    "df_train['dayofweek'] = df_train.시각.dt.dayofweek\n",
    "df_test['dayofweek'] = df_test.시각.dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime 불필요 > 제거\n",
    "df_train = df_train[df_train.columns.drop('시각')]\n",
    "df_test = df_test[df_test.columns.drop('시각')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price Variable Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_price = ['P1','P2','P3','P4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.576665</td>\n",
       "      <td>0.636191</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P2</th>\n",
       "      <td>0.576665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946439</td>\n",
       "      <td>0.576608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P3</th>\n",
       "      <td>0.636191</td>\n",
       "      <td>0.946439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P4</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.576608</td>\n",
       "      <td>0.636141</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          P1        P2        P3        P4\n",
       "P1  1.000000  0.576665  0.636191  0.999999\n",
       "P2  0.576665  1.000000  0.946439  0.576608\n",
       "P3  0.636191  0.946439  1.000000  0.636141\n",
       "P4  0.999999  0.576608  0.636141  1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train.winning==1.0, col_price].corr() # 가격변수간 상관계수 탐색(낙찰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709176</td>\n",
       "      <td>0.710066</td>\n",
       "      <td>0.999561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P2</th>\n",
       "      <td>0.709176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996453</td>\n",
       "      <td>0.719102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P3</th>\n",
       "      <td>0.710066</td>\n",
       "      <td>0.996453</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P4</th>\n",
       "      <td>0.999561</td>\n",
       "      <td>0.719102</td>\n",
       "      <td>0.719804</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          P1        P2        P3        P4\n",
       "P1  1.000000  0.709176  0.710066  0.999561\n",
       "P2  0.709176  1.000000  0.996453  0.719102\n",
       "P3  0.710066  0.996453  1.000000  0.719804\n",
       "P4  0.999561  0.719102  0.719804  1.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train.winning==0.0, col_price].corr() # 가격변수간 상관계수 탐색(유찰)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Split for Plotting\n",
    "df_win = df_train[df_train.winning==1.0]\n",
    "df_lose = df_train[df_train.winning==0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "from copy import deepcopy\n",
    "\n",
    "df_norm = deepcopy(df_train)\n",
    "\n",
    "for col in col_price:\n",
    "    df_norm[col] = (df_norm[col]-df_norm[col].mean())/df_norm[col].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalized(not-transformed) Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean-Normalized\n",
    "fig, axes = plt.subplots(2,2,figsize=(12,12))\n",
    "for idx, col in enumerate(col_price):\n",
    "    sns.kdeplot(df_norm_win[col], label='Win', ax=axes[idx//2, idx%2])\n",
    "    sns.kdeplot(df_norm_lose[col], label='Lose', ax=axes[idx//2, idx%2])\n",
    "    axes[idx//2,idx%2].legend()\n",
    "    axes[idx//2,idx%2].set_title(f'KDE Plot for {col}')\n",
    "plt.suptitle('Mean-Normalized Price Variables', fontsize=15)\n",
    "plt.show() # 32.3s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log-Transformation\n",
    "기존 분포에서는 낙찰/유찰 데이터 간의 가격변수 분포가 구분되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2,figsize=(12,12))\n",
    "for idx, col in enumerate(col_price):\n",
    "    sns.kdeplot(np.log1p(df_win[col]), label='Win', ax=axes[idx//2, idx%2])\n",
    "    sns.kdeplot(np.log1p(df_lose[col]), label='Lose', ax=axes[idx//2, idx%2])\n",
    "    axes[idx//2,idx%2].legend()\n",
    "    axes[idx//2,idx%2].set_title(f'KDE Plot for {col}')\n",
    "plt.suptitle('Log-Transformed Price Variables', fontsize=15)\n",
    "plt.show()\n",
    "plt.savefig('logtransfomred.png', transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 최종 : P1-P4 데이터에 대해 Logarithm-Tranformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_price:\n",
    "    df_train[col] = np.log1p(df_train[col])\n",
    "    df_test[col] = np.log1p(df_test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type / Variable Name Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.columns.drop(['winning']).tolist() + ['winning']] # label 마지막으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['ADID_type', 'DSP_ID', 'Media_ID', 'Adunit_ID', 'Platform', 'OS_type', 'Size_ID',\n",
    "       'Ex_Rate', 'Category', 'Country_ID', 'P1', 'P2', 'P3', 'P4', 'weekend',\n",
    "       'hour', 'dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = colnames + ['Class']\n",
    "df_test.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_int = ['ADID_type', 'DSP_ID', 'Media_ID', 'Adunit_ID', 'Platform', 'OS_type', 'Size_ID',\n",
    "           'Country_ID', 'weekend', 'hour', 'dayofweek'] # integer type columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADID_type           0\n",
       "DSP_ID              0\n",
       "Media_ID            0\n",
       "Adunit_ID           0\n",
       "Platform            0\n",
       "OS_type             0\n",
       "Size_ID             0\n",
       "Ex_Rate             0\n",
       "Category      5732131\n",
       "Country_ID       5536\n",
       "P1                  0\n",
       "P2                  0\n",
       "P3                  0\n",
       "P4                  0\n",
       "weekend             0\n",
       "hour                0\n",
       "dayofweek           0\n",
       "Class               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check NA\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value at Country_ID > treat with Mode\n",
    "df_train['Country_ID'] = df_train.Country_ID.fillna(df_train.Country_ID.mode()[0])\n",
    "df_test['Country_ID'] = df_test.Country_ID.fillna(df_test.Country_ID.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set integer columns\n",
    "df_train[col_int] = df_train[col_int].astype('int64')\n",
    "df_test[col_int] = df_test[col_int].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Treatment\n",
    "- 모든 서브카테고리까지 포함하기에는 너무 많은 variable 생성됨</br>\n",
    "- 특정 Main Category(0~26, 0:NA)에 속하는 여부만 파악\n",
    "> 동시에 여러 카테고리에 속할 경우, 가장 많은 Subcategory를 가진 main category 선택 \\\\\n",
    "> 같은 개수의 subcategory일 경우, 가장 앞에 위치한 main category 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category fillna with str NA\n",
    "df_train.Category = df_train.Category.fillna('NA')\n",
    "df_test.Category = df_test.Category.fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8525512/8525512 [00:56<00:00, 151245.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8525512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 624142/624142 [00:05<00:00, 122563.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Category treatment\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "cat_train = []\n",
    "cat_test = []\n",
    "\n",
    "for i in tqdm(range(len(df_train))):\n",
    "    cat_train.append(df_train.Category[i].split('%2C')) # 70s\n",
    "\n",
    "print(len(cat_train))\n",
    "\n",
    "for i in tqdm(range(len(df_test))):\n",
    "    cat_test.append(df_test.Category[i].split('%2C'))\n",
    "\n",
    "print(len(cat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8525512/8525512 [00:08<00:00, 1053198.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8525512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 624142/624142 [00:00<00:00, 909325.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "cat_train_treated = [] # for train\n",
    "for ls in tqdm(cat_train):\n",
    "    ls_treated = []\n",
    "    for item in ls:\n",
    "        if item == 'NA':\n",
    "            ls_treated.append(0)\n",
    "        else:\n",
    "            if item.find('-') == -1:\n",
    "                ls_treated.append(int(item[3:]))\n",
    "            else:\n",
    "                ls_treated.append(int(item[3:item.find('-')]))\n",
    "    \n",
    "    if len(ls_treated) == 1:\n",
    "        cat_train_treated.append(ls_treated[0])\n",
    "    else:\n",
    "        cat_train_treated.append(Counter(ls_treated).most_common()[0][0])\n",
    "\n",
    "print(len(cat_train_treated))\n",
    "\n",
    "cat_test_treated = [] # for test\n",
    "for ls in tqdm(cat_test):\n",
    "    ls_treated = []\n",
    "    for item in ls:\n",
    "        if item == 'NA':\n",
    "            ls_treated.append(0)\n",
    "        else:\n",
    "            if item.find('-') == -1:\n",
    "                ls_treated.append(int(item[3:]))\n",
    "            else:\n",
    "                ls_treated.append(int(item[3:item.find('-')]))\n",
    "    \n",
    "    if len(ls_treated) == 1:\n",
    "        cat_test_treated.append(ls_treated[0])\n",
    "    else:\n",
    "        cat_test_treated.append(Counter(ls_treated).most_common()[0][0])\n",
    "\n",
    "print(len(cat_test_treated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "df_train['Category'] = cat_train_treated\n",
    "df_test['Category'] = cat_test_treated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기타 변수 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "df_train_ID_treated = deepcopy(df_train)\n",
    "df_test_ID_treated = deepcopy(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Media_ID\n",
    " - Distinct value : 456\n",
    " - 최빈값(ID=152)가 전체 데이터의 53.2% at Train\n",
    " - 152(=1), 213(=2), 그 외 나머지 값(=3)으로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8525512/8525512 [00:02<00:00, 2878781.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADID_type</th>\n",
       "      <th>DSP_ID</th>\n",
       "      <th>Media_ID</th>\n",
       "      <th>Adunit_ID</th>\n",
       "      <th>Platform</th>\n",
       "      <th>OS_type</th>\n",
       "      <th>Size_ID</th>\n",
       "      <th>Ex_Rate</th>\n",
       "      <th>Category</th>\n",
       "      <th>Country_ID</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>weekend</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>296</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.193142</td>\n",
       "      <td>3.918581</td>\n",
       "      <td>3.625407</td>\n",
       "      <td>3.842917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADID_type  DSP_ID  Media_ID  Adunit_ID  Platform  OS_type  Size_ID  \\\n",
       "0          1       7         3        296         1        1        3   \n",
       "\n",
       "   Ex_Rate  Category  Country_ID        P1        P2        P3        P4  \\\n",
       "0   1218.0        22        1012  4.193142  3.918581  3.625407  3.842917   \n",
       "\n",
       "   weekend  hour  dayofweek  Class  \n",
       "0        1     0          6      0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_media_id = []\n",
    "\n",
    "for val in tqdm(df_train_ID_treated.Media_ID):\n",
    "    if val == 152:\n",
    "        ls_media_id.append(1)\n",
    "    elif val == 213:\n",
    "        ls_media_id.append(2)\n",
    "    else:\n",
    "        ls_media_id.append(3)\n",
    "\n",
    "df_train_ID_treated.Media_ID = ls_media_id\n",
    "df_train_ID_treated.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 624142/624142 [00:00<00:00, 2722941.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADID_type</th>\n",
       "      <th>DSP_ID</th>\n",
       "      <th>Media_ID</th>\n",
       "      <th>Adunit_ID</th>\n",
       "      <th>Platform</th>\n",
       "      <th>OS_type</th>\n",
       "      <th>Size_ID</th>\n",
       "      <th>Ex_Rate</th>\n",
       "      <th>Category</th>\n",
       "      <th>Country_ID</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>weekend</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1228.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.740288</td>\n",
       "      <td>3.926596</td>\n",
       "      <td>3.633367</td>\n",
       "      <td>4.23527</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADID_type  DSP_ID  Media_ID  Adunit_ID  Platform  OS_type  Size_ID  \\\n",
       "0          1       6         1        919         1        1        1   \n",
       "\n",
       "   Ex_Rate  Category  Country_ID        P1        P2        P3       P4  \\\n",
       "0   1228.0         0        1012  4.740288  3.926596  3.633367  4.23527   \n",
       "\n",
       "   weekend  hour  dayofweek  \n",
       "0        1     0          6  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_media_id = []\n",
    "\n",
    "for val in tqdm(df_test_ID_treated.Media_ID):\n",
    "    if val == 152:\n",
    "        ls_media_id.append(1)\n",
    "    elif val == 213:\n",
    "        ls_media_id.append(2)\n",
    "    else:\n",
    "        ls_media_id.append(3)\n",
    "\n",
    "df_test_ID_treated.Media_ID = ls_media_id\n",
    "df_test_ID_treated.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Adunit_ID\n",
    " - Distinct value : 986\n",
    " - 최빈값(ID=919)가 전체 데이터의 53.2% at Train\n",
    " - 919(=1), 263(11.5% = 2), 그 외 나머지 값(=3)으로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8525512/8525512 [00:02<00:00, 2973635.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADID_type</th>\n",
       "      <th>DSP_ID</th>\n",
       "      <th>Media_ID</th>\n",
       "      <th>Adunit_ID</th>\n",
       "      <th>Platform</th>\n",
       "      <th>OS_type</th>\n",
       "      <th>Size_ID</th>\n",
       "      <th>Ex_Rate</th>\n",
       "      <th>Category</th>\n",
       "      <th>Country_ID</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>weekend</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.193142</td>\n",
       "      <td>3.918581</td>\n",
       "      <td>3.625407</td>\n",
       "      <td>3.842917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADID_type  DSP_ID  Media_ID  Adunit_ID  Platform  OS_type  Size_ID  \\\n",
       "0          1       7         3          3         1        1        3   \n",
       "\n",
       "   Ex_Rate  Category  Country_ID        P1        P2        P3        P4  \\\n",
       "0   1218.0        22        1012  4.193142  3.918581  3.625407  3.842917   \n",
       "\n",
       "   weekend  hour  dayofweek  Class  \n",
       "0        1     0          6      0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_adunit_id = []\n",
    "\n",
    "for val in tqdm(df_train_ID_treated.Adunit_ID):\n",
    "    if val == 919:\n",
    "        ls_adunit_id.append(1)\n",
    "    elif val == 263:\n",
    "        ls_adunit_id.append(2)\n",
    "    else:\n",
    "        ls_adunit_id.append(3)\n",
    "\n",
    "df_train_ID_treated.Adunit_ID = ls_adunit_id\n",
    "df_train_ID_treated.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 624142/624142 [00:00<00:00, 2617197.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADID_type</th>\n",
       "      <th>DSP_ID</th>\n",
       "      <th>Media_ID</th>\n",
       "      <th>Adunit_ID</th>\n",
       "      <th>Platform</th>\n",
       "      <th>OS_type</th>\n",
       "      <th>Size_ID</th>\n",
       "      <th>Ex_Rate</th>\n",
       "      <th>Category</th>\n",
       "      <th>Country_ID</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>weekend</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1228.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1012</td>\n",
       "      <td>4.740288</td>\n",
       "      <td>3.926596</td>\n",
       "      <td>3.633367</td>\n",
       "      <td>4.23527</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADID_type  DSP_ID  Media_ID  Adunit_ID  Platform  OS_type  Size_ID  \\\n",
       "0          1       6         1          1         1        1        1   \n",
       "\n",
       "   Ex_Rate  Category  Country_ID        P1        P2        P3       P4  \\\n",
       "0   1228.0         0        1012  4.740288  3.926596  3.633367  4.23527   \n",
       "\n",
       "   weekend  hour  dayofweek  \n",
       "0        1     0          6  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_adunit_id = []\n",
    "\n",
    "for val in tqdm(df_test_ID_treated.Adunit_ID):\n",
    "    if val == 919:\n",
    "        ls_adunit_id.append(1)\n",
    "    elif val == 263:\n",
    "        ls_adunit_id.append(2)\n",
    "    else:\n",
    "        ls_adunit_id.append(3)\n",
    "\n",
    "df_test_ID_treated.Adunit_ID = ls_adunit_id\n",
    "df_test_ID_treated.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('data/train.pkl')\n",
    "df_test.to_pickle('data/test.pkl')\n",
    "df_train_ID_treated.to_pickle('data/train_ID_treated')\n",
    "df_test_ID_treated.to_pickle('data/test_ID_treated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection w. Boosting\n",
    "CatBoost를 이용하여 Fitting 후(ID treatment 없는 데이터로), feature importance 이용 변수선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages and data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "df_train = pd.read_pickle('data/train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Dataset\n",
    "\n",
    "X = df_train.drop('Class', axis=1)\n",
    "y = df_train['Class']\n",
    "\n",
    "num_features = ['Ex_Rate','P1','P2','P3','P4']\n",
    "cat_features = X.columns.drop(num_features).tolist()\n",
    "cat_idx = [idx for idx, val in enumerate(X.columns) if val in cat_features]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.4, random_state = 123, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.5, random_state =123, stratify=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Setting\n",
    "\n",
    "clf_grid = CatBoostClassifier(\n",
    "    iterations=1000, \n",
    "    random_seed=123, \n",
    "    task_type='GPU',\n",
    "    loss_function = 'Logloss',\n",
    "    verbose=100,\n",
    "    one_hot_max_size=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid\n",
    "grid = {\n",
    "      'learning_rate' : [0.01,0.1],\n",
    "      'depth' : [4, 6, 8],\n",
    "      'l2_leaf_reg' : [1,3,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning\n",
    "grid_search_result = clf_grid.grid_search(grid, X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gridsearch result\n",
    "{'depth': 8, 'l2_leaf_reg': 5, 'learning_rate': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result\n",
    "grid_search_result['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit!\n",
    "clf_grid.fit(X_train, y_train,\n",
    "    cat_features=cat_idx,\n",
    "    verbose=100,\n",
    "    eval_set = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Score\n",
    "y_pred = clf_grid.predict(X_test, prediction_type='Class')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names = ['Lose', 'Win']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_importance = pd.Series(clf_grid.feature_importances_, index=X_train.columns)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Result\n",
    "Feature Importance가 상대적으로 낮은(0.1보다 낮은) 변수 제거\n",
    "> Platform      0.053507</br>\n",
    "> OS_type       0.000000</br>\n",
    "> Ex_Rate       0.025759</br>\n",
    "> Country_ID    0.099139</br>\n",
    "> weekend       0.059900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop = feature_importance[feature_importance<0.1] \n",
    "col_drop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Load\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection from Boosting Result\n",
    "\n",
    "X = X[X.columns.drop(col_drop.index)]\n",
    "\n",
    "# Variable Features\n",
    "num_features = ['P1','P2','P3','P4']\n",
    "cat_features = X.columns.drop(num_features).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Pipeline\n",
    "과도한 더미변수 생성을 방지하기 위해 두 ID 변수를 전처리한(3-type coding) 데이터셋(`train_ID_treated.pkl`) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer\n",
    "numeric_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(drop='first', sparse=False)\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_features),\n",
    "        (\"cat\", cat_transformer, cat_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val/Test Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.4, stratify=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit_transform\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_val = preprocessor.fit_transform(X_val)\n",
    "X_test = preprocessor.fit_transform(X_test) # 15s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed setting\n",
    "\n",
    "def def_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def_seed(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.df = X\n",
    "        self.labels = y.values\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        self.x = self.df[index]\n",
    "        self.y = self.labels[index]\n",
    "        return torch.Tensor(self.x), self.y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dim\n",
    "input_shape = X_train.shape[1]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Model\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(input_shape,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 30),\n",
    "            nn.BatchNorm1d(30),\n",
    "            nn.Dropout1d(0.1),\n",
    "            nn.Linear(30, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "# Initialize Net\n",
    "model = Classifier(input_shape = input_shape)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
    "    def __init__(self, patience=10, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
    "                            Default: 7\n",
    "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
    "                            Default: False\n",
    "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
    "                            Default: 0\n",
    "            path (str): checkpoint저장 경로\n",
    "                            Default: 'checkpoint.pt'\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Trainer\n",
    "def train_model(model, batch_size, patience, epochs, device):\n",
    "    # Logging\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    avg_train_losses = []\n",
    "    avg_valid_losses = []\n",
    "\n",
    "    # earlystopping\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    model.to(device)\n",
    "    # Trainer\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        for batch, (data, target) in enumerate(train_loader, 1):\n",
    "            data = data.to(device)\n",
    "            target = target.float().to(device)\n",
    "            # clear gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.view(-1,1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        \n",
    "        # validation\n",
    "        model.eval()\n",
    "        for data, target in val_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.float().to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.view(-1,1))\n",
    "            valid_losses.append(loss.item())\n",
    "        \n",
    "        # loss per epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        epoch_len = len(str(epochs))\n",
    "\n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f} ')\n",
    "        \n",
    "        print(print_msg)\n",
    "\n",
    "        # clear epoch list\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early Stopping\")\n",
    "            break\n",
    "        \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return model, avg_train_losses, avg_valid_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 100\n",
    "lr = 0.01\n",
    "batch_size = 8192\n",
    "patience = 5 # earlystopping criteria\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To DataLoader\n",
    "train = MyDataset(X_train, y_train)\n",
    "val = MyDataset(X_val, y_val)\n",
    "test = MyDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train!\n",
    "model, train_loss, valid_loss = train_model(model, batch_size, patience, epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "y_pred_list = []\n",
    "\n",
    "# for prediction\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(test_loader):\n",
    "        data = data.to(device)\n",
    "        y_test_pred = model(data)\n",
    "        y_pred_tag = torch.round(y_test_pred).to('cpu')\n",
    "        y_pred_list.append(y_pred_tag.detach().numpy())\n",
    "\n",
    "y_pred_list = [i.squeeze().tolist() for i in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Score\n",
    "y_true_test = y_test.values.ravel()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true_test, y_pred_list, target_names = ['Lose', 'Win']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2819cb95bedbdbf0235ea4f18636776a6258e25e4398420083407874651edca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
